"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –∏ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏
–°—Ç—Ä–æ–∏—Ç –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç VIF-–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã
"""

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º backend –±–µ–∑ GUI
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from scipy.stats import chi2_contingency, spearmanr
from config import COLUMN_CONFIG, OUTPUT_CONFIG

class CorrelationAnalyzer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –∏ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏
    """
    
    def __init__(self, data_dict):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –≤—Å–µ—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
        
        Args:
            data_dict: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç–æ–ª–±—Ü–æ–≤ –∏–∑ DataLoader
        """
        self.data_dict = data_dict
        self.correlation_matrix = None
        self.vif_scores = None
        
    def build_correlation_matrix(self):
        """
        –°—Ç—Ä–æ–∏—Ç –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –¥–ª—è –≤—Å–µ—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
        
        Returns:
            pandas.DataFrame: –ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
        """
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
        data_for_correlation = {}
        
        for col_id, col_info in self.data_dict.items():
            data_for_correlation[col_info['name']] = col_info['data']
        
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(data_for_correlation)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
        self.correlation_matrix = df.corr()
        
        print("="*OUTPUT_CONFIG['separator_length'])
        print("–ú–ê–¢–†–ò–¶–ê –ö–û–†–†–ï–õ–Ø–¶–ò–ô")
        print("="*OUTPUT_CONFIG['separator_length'])
        print(self.correlation_matrix.round(4))
        
        return self.correlation_matrix
    
    def plot_correlation_heatmap(self, save_path=None):
        """
        –°—Ç—Ä–æ–∏—Ç —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
        
        Args:
            save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        if self.correlation_matrix is None:
            self.build_correlation_matrix()
        
        plt.figure(figsize=(10, 8))
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è –≤–µ—Ä—Ö–Ω–µ–≥–æ —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–∞
        mask = np.triu(np.ones_like(self.correlation_matrix, dtype=bool))
        
        # –°—Ç—Ä–æ–∏–º —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É
        sns.heatmap(
            self.correlation_matrix,
            mask=mask,
            annot=True,
            cmap='coolwarm',
            center=0,
            square=True,
            fmt='.3f',
            cbar_kws={"shrink": .8}
        )
        
        plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π', fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
        else:
            plt.savefig('img/correlation_matrix.png', dpi=300, bbox_inches='tight')
            print("–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: img/correlation_matrix.png")
        
        plt.close()
    
    def calculate_vif(self, data):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç VIF (Variance Inflation Factor) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
        
        Args:
            data: pandas.DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            pandas.Series: VIF –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
        """
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        scaler = StandardScaler()
        data_scaled = scaler.fit_transform(data)
        data_scaled = pd.DataFrame(data_scaled, columns=data.columns)
        
        vif_data = pd.DataFrame()
        vif_data["Feature"] = data.columns
        vif_data["VIF"] = [self._vif_score(data_scaled, col) for col in data_scaled.columns]
        
        return vif_data
    
    def _vif_score(self, data, target_col):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç VIF –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
        
        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            target_col: –ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
            
        Returns:
            float: VIF –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
        """
        # –ò—Å–∫–ª—é—á–∞–µ–º —Ü–µ–ª–µ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü –∏–∑ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–æ–≤
        predictors = data.drop(columns=[target_col])
        target = data[target_col]
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
        model = LinearRegression()
        model.fit(predictors, target)
        
        # –í—ã—á–∏—Å–ª—è–µ–º R¬≤
        r_squared = model.score(predictors, target)
        
        # VIF = 1 / (1 - R¬≤)
        if r_squared == 1:
            return float('inf')  # –ü–æ–ª–Ω–∞—è –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å
        else:
            return 1 / (1 - r_squared)
    
    def analyze_multicollinearity(self):
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å —Å –ø–æ–º–æ—â—å—é VIF
        
        Returns:
            pandas.DataFrame: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ VIF
        """
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è VIF –∞–Ω–∞–ª–∏–∑–∞
        data_for_vif = {}
        
        for col_id, col_info in self.data_dict.items():
            data_for_vif[col_info['name']] = col_info['data']
        
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(data_for_vif)
        
        # –í—ã—á–∏—Å–ª—è–µ–º VIF
        self.vif_scores = self.calculate_vif(df)
        
        print("\n" + "="*OUTPUT_CONFIG['separator_length'])
        print("–ê–ù–ê–õ–ò–ó –ú–£–õ–¨–¢–ò–ö–û–õ–õ–ò–ù–ï–ê–†–ù–û–°–¢–ò (VIF-–ö–û–≠–§–§–ò–¶–ò–ï–ù–¢–´)")
        print("="*OUTPUT_CONFIG['separator_length'])
        print(self.vif_scores.round(4))
        
        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\n–ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø VIF-–ö–û–≠–§–§–ò–¶–ò–ï–ù–¢–û–í:")
        print("‚Ä¢ VIF < 5: –ú—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
        print("‚Ä¢ 5 ‚â§ VIF < 10: –£–º–µ—Ä–µ–Ω–Ω–∞—è –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å")
        print("‚Ä¢ VIF ‚â• 10: –í—ã—Å–æ–∫–∞—è –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å (—Ç—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è)")
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        high_vif = self.vif_scores[self.vif_scores['VIF'] >= 10]
        moderate_vif = self.vif_scores[(self.vif_scores['VIF'] >= 5) & (self.vif_scores['VIF'] < 10)]
        
        if len(high_vif) > 0:
            print(f"\n‚ö†Ô∏è  –í–´–°–û–ö–ê–Ø –ú–£–õ–¨–¢–ò–ö–û–õ–õ–ò–ù–ï–ê–†–ù–û–°–¢–¨ (VIF ‚â• 10):")
            for _, row in high_vif.iterrows():
                print(f"   {row['Feature']}: VIF = {row['VIF']:.2f}")
        
        if len(moderate_vif) > 0:
            print(f"\n‚ö†Ô∏è  –£–ú–ï–†–ï–ù–ù–ê–Ø –ú–£–õ–¨–¢–ò–ö–û–õ–õ–ò–ù–ï–ê–†–ù–û–°–¢–¨ (5 ‚â§ VIF < 10):")
            for _, row in moderate_vif.iterrows():
                print(f"   {row['Feature']}: VIF = {row['VIF']:.2f}")
        
        if len(high_vif) == 0 and len(moderate_vif) == 0:
            print("\n‚úÖ –ú—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç (–≤—Å–µ VIF < 5)")
        
        return self.vif_scores
    
    def get_correlation_insights(self):
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –∏ –≤—ã–¥–∞–µ—Ç –≤—ã–≤–æ–¥—ã
        
        Returns:
            dict: –°–ª–æ–≤–∞—Ä—å —Å –≤—ã–≤–æ–¥–∞–º–∏ –æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è—Ö
        """
        if self.correlation_matrix is None:
            self.build_correlation_matrix()
        
        insights = {
            'strong_correlations': [],
            'moderate_correlations': [],
            'weak_correlations': []
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (–∏—Å–∫–ª—é—á–∞–µ–º –¥–∏–∞–≥–æ–Ω–∞–ª—å)
        for i in range(len(self.correlation_matrix.columns)):
            for j in range(i+1, len(self.correlation_matrix.columns)):
                col1 = self.correlation_matrix.columns[i]
                col2 = self.correlation_matrix.columns[j]
                corr_value = self.correlation_matrix.iloc[i, j]
                
                correlation_info = {
                    'variables': f"{col1} - {col2}",
                    'correlation': corr_value
                }
                
                if abs(corr_value) >= 0.7:
                    insights['strong_correlations'].append(correlation_info)
                elif abs(corr_value) >= 0.3:
                    insights['moderate_correlations'].append(correlation_info)
                else:
                    insights['weak_correlations'].append(correlation_info)
        
        print("\n" + "="*OUTPUT_CONFIG['separator_length'])
        print("–í–´–í–û–î–´ –ü–û –ö–û–†–†–ï–õ–Ø–¶–ò–Ø–ú")
        print("="*OUTPUT_CONFIG['separator_length'])
        
        if insights['strong_correlations']:
            print("\nüî¥ –°–ò–õ–¨–ù–´–ï –ö–û–†–†–ï–õ–Ø–¶–ò–ò (|r| ‚â• 0.7):")
            for corr in insights['strong_correlations']:
                print(f"   {corr['variables']}: r = {corr['correlation']:.3f}")
        
        if insights['moderate_correlations']:
            print("\nüü° –£–ú–ï–†–ï–ù–ù–´–ï –ö–û–†–†–ï–õ–Ø–¶–ò–ò (0.3 ‚â§ |r| < 0.7):")
            for corr in insights['moderate_correlations']:
                print(f"   {corr['variables']}: r = {corr['correlation']:.3f}")
        
        if insights['weak_correlations']:
            print("\nüü¢ –°–õ–ê–ë–´–ï –ö–û–†–†–ï–õ–Ø–¶–ò–ò (|r| < 0.3):")
            for corr in insights['weak_correlations']:
                print(f"   {corr['variables']}: r = {corr['correlation']:.3f}")
        
        return insights
    
    def full_analysis(self, save_plot=False):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –∏ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏
        
        Args:
            save_plot: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ –≥—Ä–∞—Ñ–∏–∫ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
        """
        print("="*OUTPUT_CONFIG['separator_length'])
        print("–ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó –ö–û–†–†–ï–õ–Ø–¶–ò–ô –ò –ú–£–õ–¨–¢–ò–ö–û–õ–õ–ò–ù–ï–ê–†–ù–û–°–¢–ò")
        print("="*OUTPUT_CONFIG['separator_length'])
        
        # 1. –°—Ç—Ä–æ–∏–º –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
        self.build_correlation_matrix()
        
        # 2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        insights = self.get_correlation_insights()
        
        # 3. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å
        vif_results = self.analyze_multicollinearity()
        
        # 4. –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫
        if save_plot:
            self.plot_correlation_heatmap("img/correlation_matrix.png")
        else:
            self.plot_correlation_heatmap()
        
        return {
            'correlation_matrix': self.correlation_matrix,
            'vif_scores': vif_results,
            'insights': insights
        }
    
    def create_contingency_table(self, col1_id, col2_id, bins=5):
        """
        –°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É —Å–æ–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–≤—É—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        
        Args:
            col1_id: ID –ø–µ—Ä–≤–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
            col2_id: ID –≤—Ç–æ—Ä–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞  
            bins: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
            
        Returns:
            dict: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ —Ç–∞–±–ª–∏—Ü—ã —Å–æ–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç–∏
        """
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        col1_data = self.data_dict[col1_id]['data']
        col2_data = self.data_dict[col2_id]['data']
        col1_name = self.data_dict[col1_id]['name']
        col2_name = self.data_dict[col2_id]['name']
        
        print("="*OUTPUT_CONFIG['separator_length'])
        print(f"–¢–ê–ë–õ–ò–¶–ê –°–û–ü–†–Ø–ñ–ï–ù–ù–û–°–¢–ò: {col1_name.upper()} vs {col2_name.upper()}")
        print("="*OUTPUT_CONFIG['separator_length'])
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ —Å —á–∏—Ç–∞–µ–º—ã–º–∏ –ø–æ–¥–ø–∏—Å—è–º–∏
        col1_cut = pd.cut(col1_data, bins=bins)
        col2_cut = pd.cut(col2_data, bins=bins)
        
        # –°–æ–∑–¥–∞–µ–º —á–∏—Ç–∞–µ–º—ã–µ –ø–æ–¥–ø–∏—Å–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
        col1_labels = []
        col2_labels = []
        
        for i, interval in enumerate(col1_cut.cat.categories):
            left = f"{interval.left:.1f}" if not pd.isna(interval.left) else "0"
            right = f"{interval.right:.1f}" if not pd.isna(interval.right) else "‚àû"
            col1_labels.append(f"{left}-{right}")
        
        for i, interval in enumerate(col2_cut.cat.categories):
            left = f"{interval.left:.1f}" if not pd.isna(interval.left) else "0"
            right = f"{interval.right:.1f}" if not pd.isna(interval.right) else "‚àû"
            col2_labels.append(f"{left}-{right}")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤—ã–µ –ø–æ–¥–ø–∏—Å–∏
        col1_bins = col1_cut.cat.rename_categories(col1_labels)
        col2_bins = col2_cut.cat.rename_categories(col2_labels)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å–æ–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç–∏
        contingency_table = pd.crosstab(col1_bins, col2_bins, margins=True)
        
        print("\n–ù–ê–ß–ê–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –°–û–ü–†–Ø–ñ–ï–ù–ù–û–°–¢–ò:")
        print("-" * 50)
        print(contingency_table)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã
        # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫—É –∏ —Å—Ç–æ–ª–±–µ—Ü —Å –∏—Ç–æ–≥–∞–º–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–æ–≤
        observed = contingency_table.iloc[:-1, :-1].values
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã
        row_totals = observed.sum(axis=1)
        col_totals = observed.sum(axis=0)
        grand_total = observed.sum()
        
        expected = np.outer(row_totals, col_totals) / grand_total
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–º–∏ —á–∞—Å—Ç–æ—Ç–∞–º–∏
        expected_table = pd.DataFrame(
            expected,
            index=contingency_table.index[:-1],
            columns=contingency_table.columns[:-1]
        )
        
        print("\n–¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ò–ï –ß–ê–°–¢–û–¢–´:")
        print("-" * 50)
        print(expected_table.round(2))
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–π —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç
        chi2_stat, p_value, dof, expected_freq = chi2_contingency(observed)
        
        print(f"\n–ö–†–ò–¢–ï–†–ò–ô –•–ò-–ö–í–ê–î–†–ê–¢:")
        print("-" * 30)
        print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ chi2: {chi2_stat:.4f}")
        print(f"p-value: {p_value:.6f}")
        print(f"–°—Ç–µ–ø–µ–Ω–∏ —Å–≤–æ–±–æ–¥—ã: {dof}")
        
        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if p_value < 0.05:
            conclusion = "–û–¢–ö–õ–û–ù–Ø–ï–ú –≥–∏–ø–æ—Ç–µ–∑—É –æ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (p < 0.05)"
            interpretation = "–ú–µ–∂–¥—É –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –µ—Å—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–∞—è —Å–≤—è–∑—å"
        else:
            conclusion = "–ù–ï –û–¢–ö–õ–û–ù–Ø–ï–ú –≥–∏–ø–æ—Ç–µ–∑—É –æ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (p ‚â• 0.05)"
            interpretation = "–ú–µ–∂–¥—É –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –Ω–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ–π —Å–≤—è–∑–∏"
        
        print(f"–í—ã–≤–æ–¥: {conclusion}")
        print(f"–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: {interpretation}")
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ö—Ä–∞–º–µ—Ä–∞ V (–¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
        n = grand_total
        cramers_v = np.sqrt(chi2_stat / (n * (min(observed.shape) - 1)))
        
        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Å–∏–ª—ã —Å–≤—è–∑–∏
        if cramers_v < 0.1:
            strength = "–û—á–µ–Ω—å —Å–ª–∞–±–∞—è —Å–≤—è–∑—å"
        elif cramers_v < 0.3:
            strength = "–°–ª–∞–±–∞—è —Å–≤—è–∑—å"
        elif cramers_v < 0.5:
            strength = "–£–º–µ—Ä–µ–Ω–Ω–∞—è —Å–≤—è–∑—å"
        else:
            strength = "–°–∏–ª—å–Ω–∞—è —Å–≤—è–∑—å"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = {
            'observed_table': contingency_table,
            'expected_table': expected_table,
            'chi2_statistic': chi2_stat,
            'p_value': p_value,
            'degrees_of_freedom': dof,
            'cramers_v': cramers_v,
            'conclusion': conclusion,
            'interpretation': interpretation,
            'strength': strength
        }
        
        return results
    
    def plot_contingency_heatmap(self, col1_id, col2_id, bins=5, save_path=None):
        """
        –°–æ–∑–¥–∞–µ—Ç —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã —Å–æ–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç–∏
        
        Args:
            col1_id: ID –ø–µ—Ä–≤–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
            col2_id: ID –≤—Ç–æ—Ä–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
            bins: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
            save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞
        """
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        col1_data = self.data_dict[col1_id]['data']
        col2_data = self.data_dict[col2_id]['data']
        col1_name = self.data_dict[col1_id]['name']
        col2_name = self.data_dict[col2_id]['name']
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã —Å —á–∏—Ç–∞–µ–º—ã–º–∏ –ø–æ–¥–ø–∏—Å—è–º–∏
        col1_cut = pd.cut(col1_data, bins=bins)
        col2_cut = pd.cut(col2_data, bins=bins)
        
        # –°–æ–∑–¥–∞–µ–º —á–∏—Ç–∞–µ–º—ã–µ –ø–æ–¥–ø–∏—Å–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
        col1_labels = []
        col2_labels = []
        
        for i, interval in enumerate(col1_cut.cat.categories):
            left = f"{interval.left:.1f}" if not pd.isna(interval.left) else "0"
            right = f"{interval.right:.1f}" if not pd.isna(interval.right) else "‚àû"
            col1_labels.append(f"{left}-{right}")
        
        for i, interval in enumerate(col2_cut.cat.categories):
            left = f"{interval.left:.1f}" if not pd.isna(interval.left) else "0"
            right = f"{interval.right:.1f}" if not pd.isna(interval.right) else "‚àû"
            col2_labels.append(f"{left}-{right}")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤—ã–µ –ø–æ–¥–ø–∏—Å–∏
        col1_bins = col1_cut.cat.rename_categories(col1_labels)
        col2_bins = col2_cut.cat.rename_categories(col2_labels)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å–æ–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç–∏
        contingency_table = pd.crosstab(col1_bins, col2_bins)
        
        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
        plt.figure(figsize=(10, 8))
        
        sns.heatmap(
            contingency_table,
            annot=True,
            fmt='d',
            cmap='Blues',
            cbar_kws={'label': '–ß–∞—Å—Ç–æ—Ç–∞'}
        )
        
        plt.title(f'–¢–∞–±–ª–∏—Ü–∞ —Å–æ–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç–∏: {col1_name} vs {col2_name}', 
                 fontsize=14, fontweight='bold')
        plt.xlabel(col2_name, fontsize=12)
        plt.ylabel(col1_name, fontsize=12)
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
        else:
            plt.savefig(f'img/contingency_table_{col1_id}_{col2_id}.png', dpi=300, bbox_inches='tight')
            print(f"–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: img/contingency_table_{col1_id}_{col2_id}.png")
        
        plt.close()
    
    def full_contingency_analysis(self, col1_id, col2_id, bins=5, save_plot=True):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü—ã —Å–æ–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç–∏
        
        Args:
            col1_id: ID –ø–µ—Ä–≤–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
            col2_id: ID –≤—Ç–æ—Ä–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
            bins: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
            save_plot: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ –≥—Ä–∞—Ñ–∏–∫
            
        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        """
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å–æ–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç–∏
        results = self.create_contingency_table(col1_id, col2_id, bins)
        
        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
        if save_plot:
            self.plot_contingency_heatmap(col1_id, col2_id, bins)
        
        return results
    
    def spearman_correlation_analysis(self, col1_id, col2_id):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–∞–Ω–≥–æ–≤—ã–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –°–ø–∏—Ä–º–µ–Ω–∞
        
        Args:
            col1_id: ID –ø–µ—Ä–≤–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
            col2_id: ID –≤—Ç–æ—Ä–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
            
        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –°–ø–∏—Ä–º–µ–Ω–∞
        """
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        col1_data = self.data_dict[col1_id]['data']
        col2_data = self.data_dict[col2_id]['data']
        col1_name = self.data_dict[col1_id]['name']
        col2_name = self.data_dict[col2_id]['name']
        
        print("="*OUTPUT_CONFIG['separator_length'])
        print(f"–†–ê–ù–ì–û–í–´–ô –ö–û–†–†–ï–õ–Ø–¶–ò–û–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –°–ü–ò–†–ú–ï–ù–ê: {col1_name.upper()} vs {col2_name.upper()}")
        print("="*OUTPUT_CONFIG['separator_length'])
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é –°–ø–∏—Ä–º–µ–Ω–∞
        spearman_corr, spearman_pvalue = spearmanr(col1_data, col2_data)
        
        print(f"\n–ö–û–≠–§–§–ò–¶–ò–ï–ù–¢ –ö–û–†–†–ï–õ–Ø–¶–ò–ò –°–ü–ò–†–ú–ï–ù–ê:")
        print("-" * 40)
        print(f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç rho: {spearman_corr:.4f}")
        print(f"p-value: {spearman_pvalue:.6f}")
        
        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if spearman_pvalue < 0.05:
            significance = "–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è (p < 0.05)"
        else:
            significance = "–ù–ï —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è (p ‚â• 0.05)"
        
        print(f"–ó–Ω–∞—á–∏–º–æ—Å—Ç—å: {significance}")
        
        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Å–∏–ª—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        abs_corr = abs(spearman_corr)
        if abs_corr < 0.1:
            strength = "–û—á–µ–Ω—å —Å–ª–∞–±–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è"
        elif abs_corr < 0.3:
            strength = "–°–ª–∞–±–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è"
        elif abs_corr < 0.5:
            strength = "–£–º–µ—Ä–µ–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è"
        elif abs_corr < 0.7:
            strength = "–°–∏–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è"
        else:
            strength = "–û—á–µ–Ω—å —Å–∏–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è"
        
        print(f"–°–∏–ª–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏: {strength}")
        
        # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        if spearman_corr > 0:
            direction = "–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è (–ø—Ä—è–º–∞—è —Å–≤—è–∑—å)"
        elif spearman_corr < 0:
            direction = "–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å)"
        else:
            direction = "–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏"
        
        print(f"–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {direction}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        spearman_results = {
            'correlation_coefficient': spearman_corr,
            'p_value': spearman_pvalue,
            'significance': significance,
            'strength': strength,
            'direction': direction,
            'interpretation': f"–ú–µ–∂–¥—É {col1_name} –∏ {col2_name} –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è {strength.lower()}"
        }
        
        return spearman_results
